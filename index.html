<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Pro Motion Detector (Telegram Only)</title>
    <style>
        body { font-family: sans-serif; background-color: #222; color: #eee; text-align: center; margin: 0; padding: 0; }
        #container { position: relative; width: 100%; max-width: 800px; margin: 0 auto; } /* Adjust max-width as needed */
        #videoElement { width: 100%; display: block; border: 3px solid #4CAF50; }
        #diffCanvas { position: absolute; top: 0; left: 0; width: 100%; height: 100%; pointer-events: none; display: none; /* Hidden by default */ }
        #status { margin-top: 10px; font-weight: bold; }
        .motion-detected { border-color: red; }
    </style>
</head>
<body>
    <h1>Pro Motion Detector</h1>
    <div id="container">
        <video id="videoElement" autoplay muted playsinline></video>
        <canvas id="diffCanvas"></canvas>  {/* Canvas for visualizing the differences */}
    </div>
    <div id="status">Starting...</div>

    <script>
        const TELEGRAM_BOT_TOKEN = '7785386019:AAHN8h2fje-njjcvAUUftx6TjJFE7rB4lvk'; // REPLACE
        const CHAT_ID = '8101021767'; // REPLACE
        const video = document.getElementById('videoElement');
        const diffCanvas = document.getElementById('diffCanvas');
        const diffCtx = diffCanvas.getContext('2d');
        const statusDiv = document.getElementById('status');

        let previousFrame = null;
        const motionThreshold = 25; // Adjust sensitivity (lower = more sensitive)
        const cooldownPeriod = 2000; // 2 seconds between captures
        let lastCaptureTime = 0;
        let isProcessing = false;

         // For visualizing differences (optional)
        const showDiff = false; // Set to true to see the difference canvas

        function handleError(message, error) {
            console.error(message, error);
            statusDiv.textContent = `Error: ${message}`;
            statusDiv.style.color = 'red';
        }

        async function startCamera() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: { facingMode: "environment", width: { ideal: 1280 }, height: { ideal: 720 } },
                    audio: false
                });
                video.srcObject = stream;
                video.onloadedmetadata = () => {
                    diffCanvas.width = video.videoWidth;
                    diffCanvas.height = video.videoHeight;
                    diffCanvas.style.display = showDiff ? 'block' : 'none'; // Show/hide diff canvas
                    statusDiv.textContent = "Camera ready. Detecting motion...";
                    requestAnimationFrame(processFrame);
                };
            } catch (err) {
                handleError("Could not access the camera.", err);
            }
        }

        function grayscale(imageData) {
            const data = imageData.data;
            for (let i = 0; i < data.length; i += 4) {
                const avg = (data[i] + data[i + 1] + data[i + 2]) / 3;
                data[i] = avg;
                data[i + 1] = avg;
                data[i + 2] = avg;
            }
            return imageData;
        }

         // Improved motion detection with region of interest (ROI)
        function detectMotion(currentFrame, previousFrame) {
              if (!previousFrame) {
                return false; // No motion if no previous frame
              }

            let motionDetected = false;
            const diff = diffCtx.createImageData(diffCanvas.width, diffCanvas.height);
            const diffData = diff.data;

             // Define a region of interest (ROI) - Example: Central 50% of the frame
            const roiX1 = Math.floor(diffCanvas.width * 0.25);
            const roiY1 = Math.floor(diffCanvas.height * 0.25);
            const roiX2 = Math.floor(diffCanvas.width * 0.75);
            const roiY2 = Math.floor(diffCanvas.height * 0.75);
              let motionPixels = 0;
            const totalPixels = (roiX2 - roiX1) * (roiY2 - roiY1);


              for (let y = roiY1; y < roiY2; y++) {
                for (let x = roiX1; x < roiX2; x++) {
                    const index = (y * diffCanvas.width + x) * 4;

                    const totalDifference = Math.abs(currentFrame.data[index] - previousFrame.data[index]);

                    if (totalDifference > motionThreshold) {
                        diffData[index] = 255; // Red for motion
                        diffData[index + 1] = 0;
                        diffData[index + 2] = 0;
                        diffData[index + 3] = 255; // Alpha
                         motionPixels++;
                        motionDetected = true;
                    } else {
                        diffData[index] = 0;      // Black for no motion
                        diffData[index + 1] = 0;
                        diffData[index + 2] = 0;
                        diffData[index + 3] = 255; // Fully opaque
                    }
                }
            }

            if (showDiff) {
                diffCtx.putImageData(diff, 0, 0); // Display the difference image
            }
            const motionPercentage = (motionPixels / totalPixels) * 100
              return motionPercentage > 5; // Consider it motion if more than 5% of pixels changed
        }



       async function processFrame() {
          if (isProcessing) {
                requestAnimationFrame(processFrame);
                return;
            }
            isProcessing = true;
            diffCtx.drawImage(video, 0, 0, diffCanvas.width, diffCanvas.height); // Draw to canvas
            const currentFrame = grayscale(diffCtx.getImageData(0, 0, diffCanvas.width, diffCanvas.height));

            if (detectMotion(currentFrame, previousFrame)) {
              video.classList.add("motion-detected");
                const currentTime = Date.now();
                if (currentTime - lastCaptureTime > cooldownPeriod) {
                    statusDiv.textContent = "Motion detected! Capturing...";
                    captureAndSendImage();
                    lastCaptureTime = currentTime;
                }
            }
            else
            {
                video.classList.remove("motion-detected")
            }

            previousFrame = currentFrame;
            isProcessing = false;
            requestAnimationFrame(processFrame);
        }



       async function captureAndSendImage() {
             diffCanvas.toBlob(async (blob) => {
                if (!blob) {
                    handleError("Failed to create image blob.");
                    return;
                }

                const formData = new FormData();
                formData.append('chat_id', CHAT_ID);
                formData.append('photo', blob, 'motion_capture.jpg'); // Use JPEG

                try {
                    const response = await fetch(`https://api.telegram.org/bot${TELEGRAM_BOT_TOKEN}/sendPhoto`, {
                        method: 'POST',
                        body: formData,
                    });
                    const data = await response.json();
                    if (data.ok) {
                        statusDiv.textContent = `Image sent at ${new Date().toLocaleTimeString()}`;
                        statusDiv.style.color = 'green';
                    } else {
                        handleError("Telegram API Error", data);
                    }
                } catch (error) {
                    handleError("Failed to send image.", error);
                }
            }, 'image/jpeg', 0.8);  // JPEG with 80% quality
        }

        startCamera();
    </script>
</body>
</html>
