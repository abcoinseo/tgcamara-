<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Pro Motion Detector (Telegram, Multi-ROI)</title>
    <style>
        body { font-family: sans-serif; background-color: #222; color: #eee; text-align: center; margin: 0; padding: 0; }
        #container { position: relative; width: 100%; max-width: 800px; margin: 0 auto; }
        #videoElement { width: 100%; display: block; border: 3px solid #4CAF50; }
        #diffCanvas { position: absolute; top: 0; left: 0; width: 100%; height: 100%; pointer-events: none; display: none; /* Hidden */ }
        #status { margin-top: 10px; font-weight: bold; }
        .motion-detected { border-color: red; }
    </style>
</head>
<body>
    <h1>Pro Motion Detector (Multi-ROI)</h1>
    <div id="container">
        <video id="videoElement" autoplay muted playsinline></video>
        <canvas id="diffCanvas"></canvas>
    </div>
    <div id="status">Starting...</div>

    <script>
        const TELEGRAM_BOT_TOKEN = '7785386019:AAHN8h2fje-njjcvAUUftx6TjJFE7rB4lvk'; // REPLACE
        const CHAT_ID = '8101021767'; // REPLACE
        const video = document.getElementById('videoElement');
        const diffCanvas = document.getElementById('diffCanvas');
        const diffCtx = diffCanvas.getContext('2d');
        const statusDiv = document.getElementById('status');

        let previousFrame = null;
        const motionThreshold = 25;
        const cooldownPeriod = 2000;
        let lastCaptureTime = 0;
        let isProcessing = false;

        // Define multiple Regions of Interest (ROIs)
        const rois = [
            { x1: 0.1, y1: 0.1, x2: 0.4, y2: 0.4, color: 'red' },   // Top-left
            { x1: 0.6, y1: 0.1, x2: 0.9, y2: 0.4, color: 'green' }, // Top-right
            { x1: 0.3, y1: 0.6, x2: 0.7, y2: 0.9, color: 'blue' }   // Bottom-center
        ];

        // For visualizing the ROIs (optional)
        const showROIs = true; // Set to true to see the ROI outlines

        function handleError(message, error) {
            console.error(message, error);
            statusDiv.textContent = `Error: ${message}`;
            statusDiv.style.color = 'red';
        }

        async function startCamera() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: { facingMode: "user", width: { ideal: 1280 }, height: { ideal: 720 } }, // Front camera
                    audio: false
                });
                video.srcObject = stream;
                video.onloadedmetadata = () => {
                    diffCanvas.width = video.videoWidth;
                    diffCanvas.height = video.videoHeight;
                    statusDiv.textContent = "Camera ready. Detecting motion...";
                    requestAnimationFrame(processFrame);
                };
            } catch (err) {
                handleError("Could not access the camera.", err);
            }
        }

        function grayscale(imageData) {
            const data = imageData.data;
            for (let i = 0; i < data.length; i += 4) {
                const avg = (data[i] + data[i + 1] + data[i + 2]) / 3;
                data[i] = avg;
                data[i + 1] = avg;
                data[i + 2] = avg;
            }
            return imageData;
        }

      function detectMotionInROIs(currentFrame, previousFrame) {
        if (!previousFrame) {
            return false;
        }

        let motionDetected = false;
        diffCtx.clearRect(0, 0, diffCanvas.width, diffCanvas.height); // Clear for ROI drawing

        for (const roi of rois) {
            const roiX1 = Math.floor(diffCanvas.width * roi.x1);
            const roiY1 = Math.floor(diffCanvas.height * roi.y1);
            const roiX2 = Math.floor(diffCanvas.width * roi.x2);
            const roiY2 = Math.floor(diffCanvas.height * roi.y2);

            let motionPixels = 0;
            const totalPixels = (roiX2 - roiX1) * (roiY2 - roiY1);

            for (let y = roiY1; y < roiY2; y++) {
                for (let x = roiX1; x < roiX2; x++) {
                    const index = (y * diffCanvas.width + x) * 4;
                    const totalDifference = Math.abs(currentFrame.data[index] - previousFrame.data[index]);

                    if (totalDifference > motionThreshold) {
                        motionPixels++;
                        motionDetected = true; // Set to true if motion in *any* ROI
                    }
                }
            }

             const motionPercentage = (motionPixels / totalPixels) * 100;

            // Draw ROI outlines (if enabled)
            if (showROIs) {
                 diffCtx.strokeStyle = roi.color;
                diffCtx.lineWidth = 2;
                diffCtx.strokeRect(roiX1, roiY1, roiX2 - roiX1, roiY2 - roiY1);
            }
             if (motionPercentage > 5) return true // if detect return 
        }

        return motionDetected; // Return the overall motion detection result
    }

      async function processFrame() {
        if (isProcessing) {
            requestAnimationFrame(processFrame);
            return;
        }
        isProcessing = true;

        diffCtx.drawImage(video, 0, 0, diffCanvas.width, diffCanvas.height);
        const currentFrame = grayscale(diffCtx.getImageData(0, 0, diffCanvas.width, diffCanvas.height));

        if (detectMotionInROIs(currentFrame, previousFrame)) {
            video.classList.add('motion-detected');
            const currentTime = Date.now();
            if (currentTime - lastCaptureTime > cooldownPeriod) {
                statusDiv.textContent = "Motion detected! Capturing...";
                captureAndSendImage();
                lastCaptureTime = currentTime;
            }
        } else {
            video.classList.remove('motion-detected');
            statusDiv.textContent = "Waiting for motion..."; // Provide feedback
        }


        previousFrame = currentFrame;
        isProcessing = false;
        requestAnimationFrame(processFrame);
    }

       async function captureAndSendImage() {
           diffCanvas.toBlob(async (blob) => {
                if (!blob) {
                    handleError("Failed to create image blob.");
                    return;
                }

                const formData = new FormData();
                formData.append('chat_id', CHAT_ID);
                formData.append('photo', blob, 'motion_capture.jpg'); // Use JPEG

                try {
                    const response = await fetch(`https://api.telegram.org/bot${TELEGRAM_BOT_TOKEN}/sendPhoto`, {
                        method: 'POST',
                        body: formData,
                    });
                    const data = await response.json();
                    if (data.ok) {
                        statusDiv.textContent = `Image sent at ${new Date().toLocaleTimeString()}`;
                        statusDiv.style.color = 'green';
                    } else {
                        handleError("Telegram API Error", data);
                    }
                } catch (error) {
                    handleError("Failed to send image.", error);
                }
            }, 'image/jpeg', 0.8);  // JPEG with 80% quality
        }

        startCamera();
    </script>
</body>
</html>
